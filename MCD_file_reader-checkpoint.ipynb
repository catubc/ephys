{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Created on Mon Jan 20 14:48:45 2014\n",
      "#Function to get all the analog entities from the *.mcd files\n",
      "#created by the MCRack software from multichannelsystems.\n",
      "#It takes the complete file path as input and returns a\n",
      "#dictionary containing the name of each channel as a key and\n",
      "#its contents as values (numpy arrays)\n",
      "#for this to work, the following libraries for python must be installed:\n",
      "#neuroshare bindings from http://pythonhosted.org/neuroshare/\n",
      "#numpy\n",
      "#This code is distributed under:\n",
      "#creative commons attribution-shareAlike 4.0 international (CC BY-SA 4.0) license.\n",
      "#@author: andre maia chagas -\n",
      "#find this and more open source tools @\n",
      "# www.openeuroscience.wordpress.com\n",
      "#function to get the recording of the digital line from\n",
      " \n",
      "def MCD_read(MCDFilePath):\n",
      " \n",
      "    #import necessary libraries\n",
      " \n",
      "    import neuroshare as ns\n",
      "    import numpy as np\n",
      " \n",
      "    #open file using the neuroshare bindings\n",
      " \n",
      "    fd = ns.File(MCDFilePath)\n",
      " \n",
      "    #create index\n",
      " \n",
      "    indx = 0\n",
      " \n",
      "    #create empty dictionary\n",
      " \n",
      "    data = dict()\n",
      " \n",
      "    #loop through data and find all analog entities\n",
      " \n",
      "    for entity in fd.list_entities():\n",
      "        print \"looping over entities: \", entity\n",
      "        analog = 2\n",
      " \n",
      "        #if entity is analog\n",
      " \n",
      "        if entity.entity_type == analog:\n",
      " \n",
      "            #store entity in temporary variable\n",
      " \n",
      "            dummie = fd.entities[indx]\n",
      " \n",
      "            #get data from temporary variable\n",
      " \n",
      "            data1,time,count=dummie.get_data()\n",
      " \n",
      "            #create channel names\n",
      " \n",
      "            channelName = entity.label[0:4]+entity.label[23:]\n",
      " \n",
      "            #store data with name in the dictionary\n",
      " \n",
      "            data[channelName] = np.array(data1)\n",
      " \n",
      "        #increase index\n",
      " \n",
      "        indx = indx + 1\n",
      " \n",
      "    #return dictionary\n",
      " \n",
      "    return data\n",
      "\n",
      "file_name = '2015-7-23-4.mcd'\n",
      "\n",
      "data = MCD_read(file_name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "looping over entities:  <neuroshare.EventEntity.EventEntity object at 0x7fa41e028890>\n",
        "looping over entities:  <neuroshare.AnalogEntity.AnalogEntity object at 0x7fa41e028910>\n",
        "looping over entities: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " <neuroshare.AnalogEntity.AnalogEntity object at 0x7fa41e0287d0>\n",
        "looping over entities: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " <neuroshare.AnalogEntity.AnalogEntity object at 0x7fa41e028890>\n",
        "looping over entities: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " <neuroshare.AnalogEntity.AnalogEntity object at 0x7fa41e028910>\n",
        "looping over entities: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " <neuroshare.AnalogEntity.AnalogEntity object at 0x7fa41e0287d0>\n",
        "looping over entities: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " <neuroshare.AnalogEntity.AnalogEntity object at 0x7fa41e028890>\n",
        "looping over entities: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " <neuroshare.AnalogEntity.AnalogEntity object at 0x7fa41e028910>\n",
        "looping over entities: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " <neuroshare.AnalogEntity.AnalogEntity object at 0x7fa41e0287d0>\n",
        "looping over entities: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " <neuroshare.AnalogEntity.AnalogEntity object at 0x7fa41e028890>\n",
        "looping over entities: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " <neuroshare.AnalogEntity.AnalogEntity object at 0x7fa41e028910>\n",
        "looping over entities: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " <neuroshare.AnalogEntity.AnalogEntity object at 0x7fa41e0287d0>\n",
        "looping over entities: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " <neuroshare.AnalogEntity.AnalogEntity object at 0x7fa41e028890>\n",
        "looping over entities: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " <neuroshare.AnalogEntity.AnalogEntity object at 0x7fa41e028910>\n",
        "looping over entities: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " <neuroshare.AnalogEntity.AnalogEntity object at 0x7fa41e0287d0>\n",
        "looping over entities: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " <neuroshare.AnalogEntity.AnalogEntity object at 0x7fa41e028890>\n",
        "looping over entities: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " <neuroshare.AnalogEntity.AnalogEntity object at 0x7fa41e028910>\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import struct\n",
      "\n",
      "data_keys = data.keys()\n",
      "SampleFrequency = 20000.\n",
      "vscale_HP = 1.\n",
      "\n",
      "order = np.array([15, 10, 16, 11, 14, 12, 9, 8, 7, 6, 5, 4, 3, 2, 1, 13])\n",
      "\n",
      "ecp = np.zeros((16,len(data[data_keys[0]])), dtype=np.int16)\n",
      "counter=0\n",
      "for key in data_keys:\n",
      "    ecp[order[counter]-1]=data[key]*1E+7\n",
      "    print \"saving order: \", order[counter], \" data: \", key\n",
      "    #ecp[counter]=data[key]*1E+6\n",
      "    counter+=1\n",
      "\n",
      "## PLOT DATA\n",
      "# x = np.arange(0,len(ecp[0]),1.)/SampleFrequency\n",
      "\n",
      "# ax = plt.subplot(1,2,1) #Can't plot stimulus information;\n",
      "# for i in range(len(ecp)):\n",
      "#    plt.plot(x[0:10000],ecp[i][0:10000]*vscale_HP-100*i, 'r-', color='black',linewidth=1)\n",
      "\n",
      "# ax = plt.subplot(1,2,2) #Can't plot stimulus information;\n",
      "# for i in range(len(ecp)):\n",
      "#    temp_index = np.where(order==i+1)\n",
      "#    plt.plot(x[0:10000],ecp[temp_index[0][0]][0:10000]*vscale_HP-100*i, 'r-', color='black',linewidth=1)\n",
      "    \n",
      "# plt.show()\n",
      "\n",
      "##***************************************** SAVE .TSF FILE *************************************\n",
      "header = 'Test spike file '\n",
      "iformat = 1002\n",
      "n_electrodes = 16\n",
      "SampleFrequency = 20000\n",
      "vscale_HP = .1\n",
      "n_vd_samples = len(ecp[0])\n",
      "print \"n_vd_samples: \", n_vd_samples\n",
      "\n",
      "probe = [16, 1, 15, 2, 12, 5, 13, 4, 10, 7, 9, 8, 11, 6, 14, 3]\n",
      "\n",
      "SiteLoc = np.zeros((n_electrodes,2), dtype=np.int16) #Read as 1D array\n",
      "for i in range (n_electrodes):\n",
      "    SiteLoc[i][0]=0\n",
      "    SiteLoc[i][1]=i*100\n",
      "    \n",
      "file_name1 = file_name + '_1.tsf'\n",
      "#file_name2 = file_name + '_2.tsf'\n",
      "\n",
      "f1 = open(file_name1, 'wb')\n",
      "#f2 = open(file_name2, 'wb')\n",
      "\n",
      "f1.write(header)\n",
      "f1.write(struct.pack('i', iformat))\n",
      "f1.write(struct.pack('i', SampleFrequency))\n",
      "f1.write(struct.pack('i', n_electrodes))\n",
      "f1.write(struct.pack('i', n_vd_samples))\n",
      "f1.write(struct.pack('f', vscale_HP))\n",
      "for i in range (n_electrodes):\n",
      "        f1.write(struct.pack('h', SiteLoc[i][0]))\n",
      "        f1.write(struct.pack('h', SiteLoc[i][1]))\n",
      "        f1.write(struct.pack('i', i+1)) #Need to add extra value for Fortran arrays\n",
      "\n",
      "        \n",
      "# f2.write(header)\n",
      "# f2.write(struct.pack('i', iformat))\n",
      "# f2.write(struct.pack('i', SampleFrequency))\n",
      "# f2.write(struct.pack('i', n_electrodes))\n",
      "# f2.write(struct.pack('i', n_vd_samples))\n",
      "# f2.write(struct.pack('f', vscale_HP))\n",
      "# for i in range (n_electrodes):\n",
      "#         f2.write(struct.pack('h', SiteLoc[i][0]))\n",
      "#         f2.write(struct.pack('h', SiteLoc[i][1]))\n",
      "#         f2.write(struct.pack('i', i+1)) #Need to add extra value for Fortran arrays\n",
      "        \n",
      "        \n",
      "print \"Writing data\"\n",
      "for i in range(len(ecp)):\n",
      "    ecp[probe[i]-1].tofile(f1)\n",
      "    #ecp[np.where(order==i+1)[0][0]].tofile(f2)\n",
      "\n",
      "f1.write(struct.pack('i', 0)) #Write # of fake spikes\n",
      "f1.close()\n",
      "print \"DONE\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "saving order:  15  data:  elec  15\n",
        "saving order:  10  data:  elec  10\n",
        "saving order: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 16  data:  elec  16\n",
        "saving order:  11  data:  elec  11\n",
        "saving order: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14  data:  elec  14\n",
        "saving order:  12  data:  elec  12\n",
        "saving order: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9  data:  elec  09\n",
        "saving order:  8  data:  elec  08\n",
        "saving order: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7  data:  elec  07\n",
        "saving order:  6  data:  elec  06\n",
        "saving order: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5  data:  elec  05\n",
        "saving order:  4  data:  elec  04\n",
        "saving order: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3  data:  elec  03\n",
        "saving order:  2  data:  elec  02\n",
        "saving order: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1  data:  elec  01\n",
        "saving order:  13  data:  elec  13\n",
        "n_vd_samples:  13764000\n",
        "Writing data"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "DONE"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}